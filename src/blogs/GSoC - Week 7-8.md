# GSoC Week 7-8

Hey Everyone!

[~~Ah shit, here we go again~~](https://knowyourmeme.com/memes/ah-shit-here-we-go-again)

I hope, you aren't getting tired of this journey (we still have treasures to plunder!). We need to sail good ol' seas aye? 

~~One of these days my shipmates are going to stab me 23 times and all I would say is "Et tu Luffy"~~

Okay enough of my mumble-jumble. 

Today, I'll walk you through two major changes that I did in my conquest to add parallelism to our code,

1. Made `fill_data` even more parallel!

2. Added support for non-unix platforms.

## Why parallelize `fill_data` further?

`fill_data` is the function that is called upon each time we switch between *moons* or *models*. In order to prepare the data for each iteration of our prediction schema, we call upon `fill_data` so if we were predicting for 3 moons using 3 models, `fill_data` would be called upon 3 x 3 = 9 times! 

So any small change in that would result in a lot of time difference in the overall usage of things. 

Apart from that a large chunk of total time consumption is caused by the function `fill_data` so its my primary concern right now.

## Areas of interest in `fill_data`

The function `fill_data` calls upon 5 functions to prepare the data directory which are,

1. `write_dataset_controls`,

2. `prep_rodents`,

3. `prep_moons`,

4. `prep_covariates`,

5. `prep_metadata`

Now out of these, only `write_dataset_controls`, `prep_rodents` and `prep_covariates` consume any significant  amount of time since they have loops within them taking their time complexity to O(N). 

We'll be applying our implementation similar to our previous usage of `mclapply` onto them. I won't get into detail for how they were done since they are identical to our previous usage.

## Pitch-forks against Windows ðŸ˜¡

Okay, I hate to be the bear of the bad news but I am the only bearer for any kind of news so lets just get over it. 

**Windows does not support forking processes.**

That single statement just encapsulates my anger at how different processes aren't allowed to communicate with other processes in windows. 

Consider a process A which are computing something. Now we require to perform another set of function within the same program but as a different process. The reason would be to keep that function "parallel" to our currently process A. Let's call this new process as B. We *fork* our program into a *main process* A and a *child process* B. 

The process A and B both would have access to the variables and states of the program and that is a very useful addition since we can manipulate the program from different processes in real-time. Windows however cannot call upon this `fork-exec` model.  

In the forking approach, copies of the entire current version of R are created in a new core.

The alternative to this adapted by the `parallel` package in `R` is to create `clusters`.

`clusters` are basically entirely new programs run seperately from the parent program. They do not follow the `fork-exec` model rather they create complete versions of the parent program on the new core and then connect them via networking. 

Consider them in terms of a game server and its clients. The server and its clients constantly "poll" each other to exchange information in a `websocket` protocol. 

Using `clusters` work in a similar manner and this approach is considered to be *socket*approach.

Managing *sockets* is more complicated than forked processes since you have to consider how their response is actually independent of the parent process. **However using *sockets* is far slower than using *forking*.**

## Applying Socket approach

Getting straight down to business, first and foremost how do I differentiate between a `unix` and `windows` system?

The answer is simple,

`R` has this object  `.Platform` which stores the information regarding which *platform* it is being executed on (kind of intuitive). So each time a *casting* is initiated, I look up the value for `.Platform$OS.type` since it can only have two values `unix` and `windows` and further down each helper function, the value of `multiprocess` could be one of the three,

1. `unix`, signifying that forking is to be used,

2. `windows`, signifying that sockets are to be used,

3. `FALSE`, signifying that execution on a single core is to be done.

Let us consider our implementation of `mcparallel` in `cast` function,

```r
models_list <- lapply(1:nmodels, function(i) {
Â Â Â Â mcparallel(model_f(i))
})

mccollect(models_list)
```

This is how we called upon the forked processes right?

Now in order to attain a similar execution flow using sockets, we use the following method,

```r
clusters <- makeCluster(detectCores() - 1, outfile = "")

clusterExport(
Â Â Â Â cl=clusters, 
Â Â Â Â varlist=c('models_scripts'), 
Â Â Â Â envir=environment()
)

parLapply(clusters, 1:nmodels, function(i) {
    model_f(i)
})

stopCluster(clusters)
```

Now, education time! (fun. I know right? no?).

First, we create clusters using `makeCluster`, i.e. cores that we would like to utilise for our new processes.

For being on a safe side, I have set the number of cores to use as `detectCores() - 1` since its a good practice to keep a core free in situations where the system is being used and doesn't have any free resources available. What would happen is such a situation? The system would obviously crash haha. (That is a very pain-ridden laughter).

Secondly, since we are creating "new" processes, their function and variable declarations would be intact its just that the value of those said variables would be set to default. So in order to share the parent process' variables to the child processes, we use `clusterExport` to export our vector or list of variables onto our selected clusters.

Thirdly, similar to how `mclapply` was a forked approach to our native `lapply`, `parLapply` is a socket based approach to the `lapply` function. It spins up our apply calls on different sockets and waits for the completion of it all.

Finally, after the complete execution of our socket based computation, we need to manually stop those clusters since they are oblivious to the world (most children are sadly). We do that using `stopCluster` function. 

This however shouldn't be considered complete stoppage of them, this just stops their execution, *dead processes* of R still remain in the system. No worries though, these *zombies* do not consume any resources.

Now let us compare the benchmark performance for windows with unix and non-parallel methods,

```r
Unit: seconds
    expr      min       lq     mean   median       uq      max neval
  linear 77.90343 83.19043 85.13469 86.03467 88.23663 90.30831     5
 windows 69.21888 71.19202 72.29011 72.68580 74.00502 74.34884     5
    unix 54.04063 54.27428 57.15926 54.32787 60.84567 62.30782     5
```

As evident in this, `unix` performs 50% faster than on an average whereas `windows` performed 20% faster on an average. This is due to the fact that they use `sockets` to communicate with each other by `poling` so it takes a bit longer amount of time as compared to making system calls to the same process using `fork-exec` method.

## Conclusion

I am still unsatisfied with the percentage of time reduced since 50% reduction isn't a great enough feat when it comes to parallel processing. The key reason for this is that they are still essentially calling upon the same directory even in the parallel schema of things, an issue arises from this is that we cannot completely make them independent of each other since they all depend on the current state of that one directory.

However, creating duplicate directories for each *forked* process would create an unnecessarily large amount of data repository which, honestly, we don't want.

I'll be looking into a solution for this next time!

Till then, its a wrap-up for the first phase of GSoC evaluation :)

Have a great day!
